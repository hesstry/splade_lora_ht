# @package _global_

init_dict:
  model_type_or_dir: meta-llama/Llama-2-7b-hf
  model_type_or_dir_q: null
  freeze_d_model: 0
  agg: max
  fp16: true

config:
  tokenizer_type: meta-llama/Llama-2-7b-hf